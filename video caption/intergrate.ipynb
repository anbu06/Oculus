{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model=load_model('final_90.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import dump\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.models import Model, load_model\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "import os\n",
    "import tokenize\n",
    "import string\n",
    "from numpy import array\n",
    "from pickle import load\n",
    "from pickle import dump\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.utils import plot_model\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.merge import add\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import keras.backend as K\n",
    "from numpy import argmax\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_for_id(integer, tokenizer):\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == integer:\n",
    "            return word\n",
    "    return None\n",
    "# generate a description for an image\n",
    "def generate_desc(model, tokenizer, photo, max_length):\n",
    "    in_text = 'startseq'\n",
    "    for i in range(max_length):\n",
    "        sequence = tokenizer.texts_to_sequences([in_text])[0]\n",
    "        sequence = pad_sequences([sequence], maxlen=max_length)\n",
    "        yhat = model.predict([photo,sequence], verbose=1)\n",
    "        yhat = argmax(yhat)\n",
    "        word = word_for_id(yhat, tokenizer)\n",
    "        if word is None:\n",
    "            break\n",
    "        in_text += ' ' + word\n",
    "        if word == 'endseq':\n",
    "            break\n",
    "    return in_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the tokenizer\n",
    "tokenizer = load(open('tokenizer.pkl', 'rb'))\n",
    "# pre-define the max sequence length (from training)\n",
    "max_length = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataset and use features \n",
    "def extract(path):\n",
    "    model = VGG19()  #FROM https://gist.github.com/baraldilorenzo/07d7802847aaad0a35d3\n",
    "    model.layers.pop()#removes last added layer\n",
    "    model = Model(inputs=model.inputs, outputs=model.layers[-1].output)\n",
    "    features = dict()\n",
    "    files=os.listdir(path)\n",
    "    for i in range(0,len(files)):#0 to len(files)-7 in case of data as last 7 files are .txt files\n",
    "        filename = path + '/' + files[i]\n",
    "        print(filename)\n",
    "        image = load_img(filename, target_size=(224, 224,3))#Alex net Size\n",
    "        image = img_to_array(image)\n",
    "        image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "        image = preprocess_input(image)\n",
    "        feature = model.predict(image, verbose=0)\n",
    "        image_id = files[i].split('.')[0]\n",
    "        features[image_id] = feature\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "i=0\n",
    "while(True):\n",
    "    photo=extract('test')['test']\n",
    "    description = generate_desc(model, tokenizer, photo, max_length)\n",
    "    print(description)\n",
    "    break\n",
    "    # Display the resulting frame\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "count=0\n",
    "import cv2\n",
    "while(1):\n",
    "    try:\n",
    "        imgResp=urllib.request.urlopen('http://192.168.43.80/snapshot.jpg')\n",
    "        imgNp=np.array(bytearray(imgResp.read()),dtype=np.uint8)\n",
    "        img=cv2.imdecode(imgNp,-1)\n",
    "           #image=detect_image(img,yolo,all_classes)\n",
    "        path='test/'\n",
    "        cv2.imwrite(os.path.join(path,'test.jpg'),img)\n",
    "        photo=extract('test')['test']\n",
    "        description = generate_desc(model, tokenizer, photo, max_length)\n",
    "        print(description)\n",
    "    except:\n",
    "        print('error')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "description1=description[1:len(description)-1]\n",
    "print(description1)\n",
    "text=\" \"\n",
    "for i in description1:\n",
    "    text=text+i\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import serial\n",
    "import time\n",
    "import requests\n",
    "import json\n",
    "firebase_url = 'https://iot-v5-0.firebaseio.com/'\n",
    "#Connect to Serial Port for communication\n",
    "ser = \"hi\"\n",
    "#Setup a loop to send Temperature values at fixed intervals\n",
    "#in seconds\n",
    "fixed_interval = 1\n",
    "i=0\n",
    "while 1:\n",
    "  try:\n",
    "    #temperature value obtained from Arduino + LM35 Temp Sensor          \n",
    "    data_c = description\n",
    "    print ((data_c))\n",
    "    \n",
    "    #insert record\n",
    "    data = {'value':(data_c)}\n",
    "    result = requests.post(firebase_url + '/' +'/data/1.json' ,data=json.dumps((data)))\n",
    "    print('Record inserted. Result Code = ' + str(result.status_code) + ',' + result.text)\n",
    "    time.sleep(fixed_interval)\n",
    "    i=i+1\n",
    "  except IOError:\n",
    "    print('Error! Something went wrong.')\n",
    "  time.sleep(fixed_interval)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
